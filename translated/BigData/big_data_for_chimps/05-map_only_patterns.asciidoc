== 分析模式: Map-only 运算

本章我们将通篇重点讲述所谓的 'Map-only 操作'。如同C&E公司第一份工作中猩猩译员们所负责的业务那样，一个Map-only操作各自处理自己的记录。该属性使得这些操作常规并行化trivially parallelizable: 他们不需要减少自己的执行周期来承担别的工作。
本章我们将通篇重点讲述所谓的 'Map-only 操作'。如同C&E公司第一份工作中猩猩译员们所负责的业务那样，一个Map-only操作各自处理自己的记录。该属性使得这些操作常规并行化trivially parallelizable: 他们不需要减少自己的执行周期来承担别的工作。

当一个脚本仅仅只有Map-only操作时。这些Map-only操作就生成了一个Mapper-only作业，这个作业执行并行组合的流水线周期。当这些Map-only操作与structural操作（下章将讲述）结合到一起，这就与mapper或reducer阶段产生了关联（map-only发生于structural前为mapper,于其后则为reducer）。

首先我们列出所有的map-only操作并将他们归到一起，这有两个原因。一是他们相当基础，如果没有通过里边的过滤 `FILTER`或循环`FOREACH`操作很难大批量地处理数据；二是归因这些操作对性能影响的方式大致相同。由于这些操作是常规并行化的,他们高效缩放，与此同时，计算产生的开销几乎不会影响吞吐量。当流水作业时，他们的性能开销可概述为“小孩子随意享用大人的购买餐”。由于任一材料数据集规模不一，很少将预备的或随后的处理开销与减少自己执行周期所产生的开销相比较。最后，由于这些操作独立处理记录，对内存的影响微乎其微，因此，请学会将他们作为一个整体一起考虑。

=== 排除数据

模式的第一个环节聚集于如何收缩你的数据集规模，这听起来好像与初学者一直所认为的观点违背，即：所有“大数据”的要点难道不是我们要立刻开始处理所有的数据集么？最终我们也将以整个人中，而不是某个样本空间为基础开发模式，因此，为什么我们要缩小数据的规模呢？

主要原因有：我们只关注记录的一个子集：只有网页需要外部引用，只有安全事件有高威胁级别，只有少量超过100万美元的帐户。甚至当你处理一个数据集中的所有记录时，你也许只对跟你研究相关的一个字段的子集感兴趣。考虑到内存及计算效率兼顾计算的正常运转，你帮了自己一个忙，立刻对一个工作集进行筛选，使之只保留与你手头工作相关的记录和字段。
 footnote:[这肯定会简化调试。同样奏响Q的副歌， _了解你的数据_. 如果你在处理一个数据集时你不准备用到多余的字段或是记录，你能肯定他们不会莫名其妙地爬到你的模型里边去么？在这里，最坏的情况是什么被称为一个特征泄漏，在你目标中，变向风在受训数据中吹来吹去（在本质上：想象一下，只要你是第一个提供今天的高温的人，就可以说你能预测今天的高温度)。当你将一个模式应用到现实世界中时，一个特征泄漏会给你一个惊喜，一个让你痛苦的惊喜。] 而且，你也许会希望在一个持续作业上发布代码之前，在一个小小样本上测试一下。 footnote:[这是通常是开发的一个好习惯，尤其是如果你是那个在离开办公室、睡觉、登机长途飞行前才开始工作的那个人。]最后,当检验数据集中的每个元素的计算开销太过昂贵时，你也许只想取一个随机样本来抽查一个数据集。

课程的目标并不是 _排除_ 数据，而是 _选择性_ 地挑选数据，同时我们将向你介绍多种技术来完成数据的选择。


=== 选择满足一个条件的记录: `FILTER`和他的小伙伴们

排除（选择）数据的第一步是过滤掉不匹配特定标准的记录。Pig的 `FILTER` 声明可完成这个操作。它并不是消除数据 -- Hadoop中的所有数据，Pig不可改变它 -- 所有的Pig运算更像是创建了一个新的表，这个表从输入中删掉了特定的记录。

在计的棒球比赛可追溯到1871年(!)，但发展了数十年才有了现代棒球比赛形式的稚形。可以说我们只对1900后的赛季感兴趣。在Pig中，我们用 `FILTER` 运算footnote:[在这个以及以后的脚本中，除非有必要使用，我们将省略掉 `LOAD`，`STORE` 及其他的这样的声明。全部可执行的代码请参见代码(REF)的示例]:

------
modern_stats = FILTER bats BY (year_id >= 1900);
------

目前你所期望看到的比赛被条件范围所限定：`==`（双等于）表示等式，`!=` 表示非，`>`, `>=`, `<`, `<=` 不等式，`IN` 指列表中是否存在与之匹配的记录； `MATCHES` 字符串模式匹配。（最后两种表达在一个式子中可以执行多匹配）。

==== 选择满足多条件的记录

在一次数据搜索中，通常来说用稀疏数据来排除主题是很重要，要么消除小数据样本的伪数，要么由于他们不在本次感兴趣的关注点之内。在本次案例中，我们通常想要将分析约束在常规选手之内 -- 那些在一个赛季中在较受关注的比赛时间内上场的棒球员 -- 同时允许损伤或情景置换。自在一个赛季的154到162场比赛中，大联盟球员平均击球4次以上后（该击球数在1960年有所增加），我们可以得到450个样板表现（几乎占了最大数目的2/3）来作为我们的阈值，450PA这个数字 footnote:[绝非偶然，450PA这个数字接近于“合格”赛季的阈值-每个球队需得到3.1样板表现才能获得季赛参与奖]。

在Pig脚本中，你同样能用`AND`, `OR`, `NOT`来组合条件声明，下边的选择语句让我们称之为“合格的现代赛季”：常规选手，在新时代比赛竞争，隶属于两大现代联盟中的任意一个。

------
modsig_stats = FILTER bats BY
  (PA >= 450) AND (year_id >= 1900) AND ((lg_id == 'AL') OR (lg_id == 'NL'));
------

==== 用空（ `null`）值来选择或排除记录

`people` 表是另外一个我们将要处理的表。它描述了棒球选手们个体相关的关键统计资料：姓名，出生日期、地点，死亡日期、地点，棒球职业生涯开始时间跟结束时间；身高、体重等等。这些数据非常全面，但在某些情况下某些字段会存在空（`null`）值。在很多情况下空值被实际使用：

* _丢失/未知值_ -- 此情况适于小部分早期球员的出生地点和出生日期
* _无可用值_ -- 仍活着的棒员队员拥有`null` 的死亡日期跟死亡地点
* _缺陷值_ -- 如果一个错误的界线创造了一个不可解析的单元（如将 `'Bob'`写入数据类型为整形的一个字段），Pig将在日志中写入一个警告，同时将`null`值写入其中。
* _非法值_ -- 被零除或类似的错误操作结果用空值（同时不报错，不警告，不日志声明）
* _"其他"_ -- 人们通常使用空（`null`）值代表“它很复杂，但也许其他的字段存储着它的细节信息”.

使用`FILTER`声明我们能够排除那些出生日期及地点未知的棒球队员:

------
borned = FILTER people BY (birth_year IS NOT NULL) AND (birth_place IS NOT NULL);
------

对于有SQL背景的人来说，它对Pig对空（`null`）值的处理相当熟悉。其他人，同样幸运，在不给出操作提示或与 `null` 进行比较（这意味着其结果既不假`false` 也不真 `true`）的时候空值通常会消失，因此`null`不小于5.0，也不大于5.0，同样不等于5.0。一个空值不等于`null`，也非_不等于_`null`。可想而知程序员要跟踪所有的空值是多么难了。在Pig操作手册中所有这些规则的复杂的集合都有很详细的说明，因此在这儿我们将不再深入 -- 看大量的示例是我们发现你所需要的最好的学习方式，我们努力提供了大量丰富的示例供大家学习。

===== 模式使用

在我们讲完任一种模式或模式组后，我们会将如下所示的块呈现在读者面前。由于不是什么有趣的事情要说，故不是每一个字段每次都会出现。

* _应用场景_  -- (_商业或编程环境。_) 任何地点。就像是你照相机的光圈，成像的开始跟结束时你都用它来调节光线。
* _规范代码_	 -- ( _我们只提供足够让你记住它是如何拼写的代码段_) `somerecords = FILTER myrecords BY (criteria AND criteria ...);`
* _SQL用户，你好_     -- (_相关SQL命令的一个草图，有SQL经验背景的人的重要注意事项_) `SELECT bat_season.* FROM bat_season WHERE year_id >= 1900;`
* _重要事项_	 -- (_使用的注意事项。你不理解/不能通过本书第一时间买进但之后你可能会理解的事项。_)
  - 早过滤，常过滤。将一个大的数据集变小是你所能做的最好的事情。
  - SQL用户请注意: 请使用`==`, `!=` -- 而不是 `=` 或其他。
  - 程序员请注意: 请使用`AND`, `OR` -- 而不是 `&&`, `||`。
* _计数输出_	 -- (_输出多少记录: 很少, 一些, 更多, 爆增？_) 从0到100%的输入记录计数。计数输出的数据规模将相应减少。
* _记录_		 -- (_进行这项操作的那些相似记录的草图_) 相同的输入
* _数据流_		 -- (_该操作生成Hadoop作业。本章，所有的流水线跟这个类似，下章将会不同_) Map-Only: 数据流构成于上述map 或 reduce的结束阶段，如果它单独存在，就成为一个 map-only 作业。
* _供你练习_    -- (_如果你选择，请发扬这样一种理念。不要去寻找答案部分 --  我们没有提供任何答案。很多情况下你首先会去寻找答案_)，与`null`们和条件操作符一起玩耍，直到你对它的怪癖（特殊用法）感觉良好。
* _另请参阅_             -- (_除了本书此章节中的模式外，其他哪些哪些主题能够应用此模式？有时在本书的另外一章中，有时是其他地方的一个指针_) 不同的运算，有些是集合Set运算，有些连接Joins运算同样用来根据一些标准来排除记录。请特别注意半连接和反连接 the Semi-Join and Anti-Join (REF),它们不靠一张大的关键字列表来选择或是排除匹配的记录。


==== 通过匹配正则表达式来筛选记录(`MATCHES`)

一个 `MATCHES` 表达式采用正则表达式模式来匹配字符串值.正则表达式以纯 `chararray` 字符串来给出;像Python/Ruby/Perl/etc-ists所希望的那样，它没有特殊的语法。参见重要明细及参考的工具栏（REF），它将帮助你掌握该重要的工具。

该运算使用了一个正则表达式来筛选其名字跟你任意一个作者的名字相似的棒球队员:

------
-- Name contains a Q; is `Flip` or anything in the Philip/Phillip/... family. (?i) means be case-insensitive:
namesakes = FILTER people BY (nameFirst MATCHES '(?i).*(q|flip|phil+ip).*');
------

人们很容易忘记人的名字中包含空格，点，破折号，撇号，以小写字母或以撇号开头，带有重音或是其他非拉丁字符 footnote:[示例的一般性原则这如果你认为涉及到人有关的分析很简单，那就大错特错了]. 因此作为 `MATCHES`的一个不那么傻的示例，本代码段抽取了所有不以大写字母、不以非词或不以非空格开头的名字:

------
funnychars = FILTER people BY (nameFirst MATCHES '^([^A-Z]|.*[^ws]).*');
------

你可以: 非常明确的说明，这些只是Java的正则表达式，并指出·可可。
你可以TODO: 也许你可以将下边的文本重组为“怎么将一个sane 正则表达式转换为一个Pig/Java正则表达式”。

有很多非词或非空格开头的名字，但没有人的名字以小写字母开头。然而在本书早期的拟稿中该查询通过"nameFirst" 值查询到了一个记录 -- 源文件的头行污染了这个表。本书现在修正了这个错误，像这样理智的检查永远不会过时，尤其是在大数据中。当你有数十亿的记录时，百万分之一的异常会出现数千次。

.关于字符串匹配的重要事项
******
正则表达式无比强大，我们希望所有的读者对其有基础的认识。比从http://regexp.info[regexp.info]网站上掌握它，再没有其他更好的方式了。在本书的结尾（REF）我们提供了一个简要的备忘录。对于Pig，尤其有必要对其作出必要的澄清:

* 在Pig中用于MATCHES运算的正则表达式以纯字符串出现。用一个反斜杠为字符串的字面意思服务，当送给正则表达式引擎时它不出现在字符串中。通过缩写 `[^ws]` (非词 非空格单词)，我们需要使用两个反斜杠。

* 是的，在一个目标字符串中匹配一个反斜杠符号需要使用四个反斜杠: ``!
* 字符串中匹配中可供选择的选项。例如`(?i)` 指做不区分大小写(如同上面所做的那样)匹配时使用， `(?m)` 用来多行匹配等等 -- 参见参考资料。

* Pig正则表达式在字符串的开冻跟结尾隐式加上了固定的字符，相当于在开头加上了 `^` ，在结尾加上了 `$` 。（这与Java类似但与很多其他的语言不同。），像我们上面所做的，在两个结尾处使用`.*` ，恢复传统的“贪婪”的行为。当写正则表达式时明确地写上 `^` or `$` 这对可读性来说个好习惯。


* `MATCHES`是一个表达式，就像 `AND` 或 `==` -- 你写下 `str MATCHES regexp`。另一个你将接触的正则表达式机制是函数 -- you write `REGEX_EXTRACT(str, regexp, 1)`。当完成本书的课程时，你将忘记我们告诉过你。
* 正则表达式结果产出包括: Peek-A-Boo Veach, Quincy Trouppe, and Flip Lafferty。
* 从记录中你被允许使正则表达式成为一个值，尽管Pig正则表达式能以一个很好的加速比预编译常数正则表达式。
* Pig不能提供一个与SQL `%` 完全相等的表达式做简易匹配。点星 (`.*`)粗略等价于SQL `%`（零个或多个任意字符），点粗略等价于SQL `_`（单字符）；方括号（例如 `[a-z]`）粗略等价于SQL的一个字符范围。
* 字符串等式区分大小写: `'Peek-A-Boo'` 不等于 `'peek-a-boo'`  。对于不区分大小写的字符串匹配，可调用 `EqualsIgnoreCase` 函数：`EqualsIgnoreCase('Peek-A-Boo', 'peek-a-boo')` 为真。这只是调用Java的 `String.equalsIgnoreCase()` 方法，其不支持正则表达式。
******

NOTE: 遗憾的是，虽然大家都知道获得诺贝尔的物理学家无论是 Gerard 't Hooft, Louis-Victor Pierre Raymond de Broglie, 还是 Tomonaga Shin'ichirō没有参加或尝试加入职棒大联盟。可当处理名字的时候，他们的名字经常被作为反例被记住。 Prof de Broglie的全名占38个字符，有一个姓以小写字母开头，不能按常规方式进行切割。"Tomonaga" 是名字的姓，尽管它放在名字的最前面。你会看到 Tomonaga教授的名字给出了各种各样的写法像"Tomonaga Shin'ichirō", "Sin-Itiro Tomonaga",或"朝永 振一郎"，在不同的上下文中他们任一个都可能是正确的，当然随之其他就是错误的。't Hooft教授的姓以一个撇号一个小写字母开头，并含有一个空格。我们建议你最好在你的工作间放置一个古玩架子来收集诸如此类的反例，本书将会向读者分享一些这样例子。

===== 模式使用

* _应用场景__  -- 无论在哪儿你都需要用字符串字段来筛选记录。
选择对小表，寻找缺陷记录。匹配复合键的一个分段 -- 你能明白 `games` 表上执行`game_id MATCHES '...(19|20).*'` 这条语句能做什么么？
* _规范代码_	 -- `FILTER recs BY (str MATCHES '.*pattern.*')`, 当然, 而且要加上 `FOREACH recs GENERATE (str MATCHES '.*(kitty|cat|meow).*' ? 'cat' : 'notcat') AS catness`.
* _SQL用户，你好_     -- 与 `LIKE` 类似但比它更强大。详见转换指南中的侧边栏sidebar (ref) 。
* _重要事项_	 --
  - 更主要的是，他们都异常强大，尽管现在他们看起来很神秘，但事实上他们要比想象中更容易。
  - 与Pig提供的大多数其他字符串条件函数相比，你最好把学习正则表达式当成一个额外的事来区别对待。
  - ... 其他需要我们知道的重要事项，我们将其放在了侧边栏中（REF）。
* _记录_		 --你可以在一个筛选子句中使用它，同样在任何地方的表达式中使用也是被允许的，就像前一代码中一样。
* _数据流_		 -- Map-Only: 构成于map 或 reduce的结束阶段，如果它单独存在，就成为一个 map-only 作业。
* _供你练习_    -- 遵循 http://regexp.info/tutorial.html[regexp.info 教程], 但 _看到 Grouping & Capturing那一部分就足够了_. 剩下的部分最好是当你发现你需要他时再行查阅。
* _另请参阅_             -- Pig `REGEX_EXTRACT` 及 http://pig.apache.org/docs/r0.12.0/func.html#replace[`REPLACE`] 函数。 详细的Java的 http://docs.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html#sum[正则表达式] 文档在它的pecadilloes中 (请不要看成是对正则表达式的培训)。


==== 在一个固定查找表中匹配值来筛选记录

如果你打算通过匹配小型静态列表值来进行过滤，Pig提供了方便的 `IN` 表达式：如果其值等于（区分大小写）列表中的任意一个值，返回真。这筛选出了每年被东部棒球区现今球队使用的体育馆:

------
al_east_parks = FILTER park_team_years BY
  team_id IN ('BAL', 'BOS', 'CLE', 'DET', 'ML4', 'NYA', 'TBA', 'TOR', 'WS2');
------

有时使用一个正则表达式来代替它是一个正确的选择。显然，`bubba MATCHES 'shrimp (kabobs|creole|gumbo|soup|stew|salad|and potatoes|burger|sandwich)' OR bubba MATCHES '(pineapple|lemon|coconut|pepper|pan.fried|deep.fried|stir.fried) shrimp'` 语句的可读性比 `bubba IN ('shrimp kabobs', 'shrimp creole', 'shrimp gumbo', ...)`语句要高。

当供匹配的列表变得有点大,将其读到一个组成员数据结构中不失为一个明智的选择 footnote:[如Ruby，一个动态语言, 比起分析数据文件，它往往可以更快和更清洁的格式化表到语言本身。加载出表格数据就是一个笑话（特别是需要查询表格时），比起翻译Rubyy语言，没有什么能比Ruby翻译器译得更快了。],但最终大数据集以数据文件形式
存在。

通常情况下使用连接来处理埠，我们在下一章节"在另外的表进行匹配来筛选记录（半连接）"下（REF）中对此作出说明。尤其要注意，在使用专业合并联接和哈希映射（复制）连接时，最终，你也许会发现你得到了一张超级大的表，然后表中只有一丁丁的元素能被匹配上。在这种情况下，使用布隆过滤比较合适，我们将在统计学章节对布隆过滤做更多的讲解，在一个大的文档集中使用布隆过滤器匹配一张一个大的地名列表来筛选每一个地名。

// 扩展: 添加事件声明

===== 模式使用

* _应用场景_  -- 从网络日志中选择或排除文件类型或IP地址。其关键是模型记录下了你通过数据流的路径，你正在研究的股票符号。与“同时总结一个集群的多子集” (REF)一起，枚举成员队列。 (`(state IN ('CA', 'WA', 'OR') ? 1 : 0) AS  is_western, ...`).
* _规范代码_	 -- `foo IN ('this', 'that', 'the_other')`, 或任何由该语句产生的变种形式。
* _SQL用户，你好_     -- 这远不如SQL的 `IN` 表达式那样强大， 更重要的是，你不能够提供另外一张表作为列表使用。
* _重要事项_	 -- 使用正则表达式来代替它是一个正确的选择。
* _计数输出_	 --即不同的值的数目，有很多记录是其键值的基数，其数据规模将大大减少。
* _数据流_		 -- Map-Only: 构成于map 或 reduce的结束阶段，如果它单独存在，就成为一个 map-only 作业。

=== 投影只通过列名选择字段

当基于表达式用一个 `FILTER` 选择 _行row_ 时，Pig的 `FOREACH` 通过列名来选择特定的 _字段_ 。我们将这个简单的操作称之为"投影"。

我们尽量使用 _project_ 使选择的列更加精准，以任何方式用 _select_ 选择行，用 _filter_ 意味着我们要选择满足特定条件表达式的行。

我们使用的表有着超级丰富的统计数据，但我们只需要一点点来做相当复杂的 搜寻。gamelogs表有90多列，使用一个FOREACH循环只抽取球队及最终的分数:

------
game_scores = FOREACH games GENERATE
  away_team_id, home_team_id, home_runs_ct, away_runs_ct;
------

==== 使用FOREACH来选择、重命名及重排序字段

不局限于简单地限定列数，你同样能够在投影中重命名、重排序列。每一个表记录有 _两个_ 比赛结果，一个为主队一个为客队。纯粹从每个团队的视角出发，我们可以在一个表数据列表结果中的同一列中列出该队作为主客队所有分数： 

------
games_a = FOREACH games GENERATE
  year_id, home_team_id AS team,
  home_runs_ct AS runs_for, away_runs_ct AS runs_against, 1 AS is_home:int;

games_b = FOREACH games GENERATE
  away_team_id AS team,     year_id,
  away_runs_ct AS runs_for, home_runs_ct AS runs_against, 0 AS is_home:int;

team_scores = UNION games_a, games_b;

DESCRIBE team_scores;
--   team_scores: {team: chararray,year_id: int,runs_for: int,runs_against: int,is_home: int}
------

第一个投影将 `home_team_id` 到团队槽中, 并重命名为 `team`; 保留 `year_id` 字段不变; 把主客队八分数分别归档到 `runs_for` 及 `runs_against` 字段下。 最后，我们设置一个代表主队的标识字段 并定义其字段名跟类型。第二步我们为客队生成一个相应的表，然后用 `UNION` 运算符（我们将用几页地篇幅对此进行介绍）将两个表堆叠到一起。所有的表都以相同的模式显示，虽然他们的值来自源表的不同列。


===== 模式使用

* _应用场景_  -- 几乎任何地点。如果 `FILTER` 是我们的相机的光圈, 这是变焦镜头。
* _规范代码_	 -- `FOREACH recs GENERATE only, some, columns;`
* _重要事项_	 -- 正如你所看到的,我们花了很多心思视觉对准到代码片段中的子表达式。这并不是因为我们已经打扫好了房间让学生住进来 --  这是我们写的代码，我们战友希望我们像这样写代码。
* _计数输出_	 -- 完全与输入保持一致。
* _记录_		 -- 无论你将他们定义成什么。
* _数据流_		 -- Map-Only: 构成于map 或 reduce的结束阶段，如果它单独存在，就成为一个 map-only 作业.
* _另请参阅_             -- "用复杂的类型拼合语句Assembling Literals with Complex Type" (REF)

==== 抽取记录的随机样本

另一个常见的运算是抽取一个 _均匀uniform_ 的样本 -- 
Another common operation is to extract a _uniform_ sample -- 每个记录被选的概率相等。例如，你可以在整个数据集中运行前用它来测试新代码(可能会由于大量误处理的记录而导致一个连续作业失败)。通过调用 `SAMPLE` 运算符, 你请求Pig随机排除掉一些记录。

以下的Pig代码从我们的棒球数据集中返回的一个10%的随机选择记录(即, 1/10 = 0.10):

------
some_seasons_samp = SAMPLE bat_seasons 0.10;
------

 `SAMPLE` 通过生成一个随机数来选择记录进行运算，这意味着任意一个运行使用 `SAMPLE` 运算符的脚本都会生成一个不同的记录集，有时他是你想要的，或至少，你不会太介意。在其他情况下，你想要一次抓取一个均匀样本，然后重复对这些 _相同_ 记录进行操作。(假定这样一个示例，对一个数据集进行现场检查的新代码：你需要对同一个样本运行你的代码来确保你的工作如预期的变化。)

有经验的软件开发员将使用一个 "seeding" 函数 -- 例如R的 `set.seed()` 或 Python的 `random.seed()` --  使记录的随机性就差那么一点点。在这个时候，  Pig没有等效的函数。更糟的是， Even worse,这是不一致的 _在任务中_ -- 如果一个机器上的一个map任务失败了, 重试将尝试生成不成的数据推送给reducers。这个不常归因的问题，但对于任何想要回馈给Pig项目的人来说, 这是一个需要解决的简单高价值问题。

